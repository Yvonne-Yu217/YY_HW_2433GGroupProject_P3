{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7841ca13",
   "metadata": {},
   "source": [
    "# Read KFF Data Files\n",
    "\n",
    "This notebook reads all data files under `2433_p3_data/KFF_data/` directory and displays the first 5 rows of each file.\n",
    "\n",
    "KFF (Kaiser Family Foundation) data files contain healthcare-related statistics and information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052898c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pandas display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3f0eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 找到数据目录: 2433_p3_data/KFF_data\n",
      "  绝对路径: /Users/mac/Desktop/Lecture_2433/group_project_251117/2433_p3_data/KFF_data\n"
     ]
    }
   ],
   "source": [
    "# Define KFF data directory\n",
    "KFF_DATA_DIR = Path('2433_p3_data/KFF_data')\n",
    "\n",
    "# Check directory exists\n",
    "if not KFF_DATA_DIR.exists():\n",
    "    print(f\"ERROR: directory {KFF_DATA_DIR} not found!\")\n",
    "else:\n",
    "    print(f\"✓ Found data directory: {KFF_DATA_DIR}\")\n",
    "    print(f\"  Absolute path: {KFF_DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc08f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取: raw_data_2020.csv... ✓ 成功 (形状: (56, 5))\n",
      "正在读取: raw_data_2021.csv... ✓ 成功 (形状: (56, 5))\n",
      "正在读取: raw_data_2022.csv... ✓ 成功 (形状: (56, 5))\n",
      "正在读取: raw_data_2023.csv... ✓ 成功 (形状: (56, 5))\n",
      "正在读取: raw_data_2024.csv... ✓ 成功 (形状: (56, 5))\n",
      "正在读取: raw_data_2025.csv... ✓ 成功 (形状: (56, 5))\n",
      "正在读取: raw_data_2026.csv... ✓ 成功 (形状: (56, 5))\n",
      "\n",
      "总计: 成功读取 7 个文件, 失败 0 个文件\n"
     ]
    }
   ],
   "source": [
    "# Read all CSV files into dictionary (robust reading, skip metadata rows and auto-detect header)\n",
    "kff_data = {}\n",
    "errors = {}\n",
    "\n",
    "def robust_read_csv(path):\n",
    "    \"\"\"Try robust reading: skip leading metadata lines, detect header line, then read with pandas.\"\"\"\n",
    "    # Read first few lines to detect header position\n",
    "    with open(path, 'r', encoding='utf-8') as fh:\n",
    "        preview = []\n",
    "        for _ in range(40):\n",
    "            try:\n",
    "                preview.append(next(fh))\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(preview):\n",
    "        # header likely contains Location or multiple commas\n",
    "        if 'Location' in line or line.count(',') >= 2:\n",
    "            header_idx = i\n",
    "            break\n",
    "\n",
    "    # If header_idx found and >0, skip that many rows so pandas uses next as header\n",
    "    if header_idx is not None and header_idx > 0:\n",
    "        df = pd.read_csv(path, skiprows=header_idx, low_memory=False)\n",
    "    else:\n",
    "        # Try normal read; if it fails, try engine='python' with flexible sep\n",
    "        try:\n",
    "            df = pd.read_csv(path, low_memory=False)\n",
    "        except Exception:\n",
    "            df = pd.read_csv(path, sep='\\t', engine='python', low_memory=False)\n",
    "    return df\n",
    "\n",
    "for file_path in data_files:\n",
    "    file_name = file_path.name\n",
    "    try:\n",
    "        print(f\"Reading: {file_name}...\", end=' ')\n",
    "        df = robust_read_csv(file_path)\n",
    "        kff_data[file_name] = df\n",
    "        print(f\"✓ Success (shape: {df.shape})\")\n",
    "    except Exception as e:\n",
    "        errors[file_name] = str(e)\n",
    "        print(f\"✗ Failed: {e}\")\n",
    "\n",
    "print(f\"\\nTotal: Successfully read {len(kff_data)} files, {len(errors)} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa3955",
   "metadata": {},
   "source": [
    "## Data Overview Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c66192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "KFF数据文件汇总\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文件名</th>\n",
       "      <th>行数</th>\n",
       "      <th>列数</th>\n",
       "      <th>总缺失值</th>\n",
       "      <th>缺失率(%)</th>\n",
       "      <th>内存使用(MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_data_2020.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw_data_2021.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raw_data_2022.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raw_data_2023.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raw_data_2024.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>raw_data_2025.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>raw_data_2026.csv</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5.71%</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 文件名  行数  列数  总缺失值 缺失率(%) 内存使用(MB)\n",
       "0  raw_data_2020.csv  56   5    16  5.71%     0.01\n",
       "1  raw_data_2021.csv  56   5    16  5.71%     0.01\n",
       "2  raw_data_2022.csv  56   5    16  5.71%     0.01\n",
       "3  raw_data_2023.csv  56   5    16  5.71%     0.01\n",
       "4  raw_data_2024.csv  56   5    16  5.71%     0.01\n",
       "5  raw_data_2025.csv  56   5    16  5.71%     0.01\n",
       "6  raw_data_2026.csv  56   5    16  5.71%     0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总行数: 392\n",
      "平均列数: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Create data overview summary table\n",
    "summary_data = []\n",
    "\n",
    "for file_name, df in sorted(kff_data.items()):\n",
    "    summary_data.append({\n",
    "        'Filename': file_name,\n",
    "        'Rows': df.shape[0],\n",
    "        'Columns': df.shape[1],\n",
    "        'Total Missing': df.isnull().sum().sum(),\n",
    "        'Missing Rate(%)': f\"{(df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\",\n",
    "        'Memory(MB)': f\"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"KFF Data Files Summary\")\n",
    "print(\"=\"*100)\n",
    "display(summary_df)\n",
    "\n",
    "print(f\"\\nTotal rows: {summary_df['Rows'].sum():,}\")\n",
    "print(f\"Average columns: {summary_df['Columns'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5ddba",
   "metadata": {},
   "source": [
    "## Check Data Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c48fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列结构一致性检查:\n",
      "  ✓ raw_data_2020.csv: 列结构一致\n",
      "  ✓ raw_data_2021.csv: 列结构一致\n",
      "  ✓ raw_data_2022.csv: 列结构一致\n",
      "  ✓ raw_data_2023.csv: 列结构一致\n",
      "  ✓ raw_data_2024.csv: 列结构一致\n",
      "  ✓ raw_data_2025.csv: 列结构一致\n",
      "  ✓ raw_data_2026.csv: 列结构一致\n",
      "\n",
      "✓ 所有文件的列结构一致，可以安全地合并!\n"
     ]
    }
   ],
   "source": [
    "# Check if all files have the same column structure\n",
    "if len(kff_data) > 0:\n",
    "    first_file = list(kff_data.keys())[0]\n",
    "    first_columns = set(kff_data[first_file].columns)\n",
    "    \n",
    "    print(\"Column structure consistency check:\")\n",
    "    all_same = True\n",
    "    \n",
    "    for file_name, df in kff_data.items():\n",
    "        current_columns = set(df.columns)\n",
    "        if current_columns == first_columns:\n",
    "            print(f\"  ✓ {file_name}: Consistent column structure\")\n",
    "        else:\n",
    "            all_same = False\n",
    "            print(f\"  ✗ {file_name}: Different column structure\")\n",
    "            missing = first_columns - current_columns\n",
    "            extra = current_columns - first_columns\n",
    "            if missing:\n",
    "                print(f\"    Missing columns: {missing}\")\n",
    "            if extra:\n",
    "                print(f\"    Extra columns: {extra}\")\n",
    "    \n",
    "    if all_same:\n",
    "        print(\"\\n✓ All files have consistent column structure, safe to merge!\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Files have inconsistent column structure, alignment needed before merging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab99cd",
   "metadata": {},
   "source": [
    "## Optional: Merge All Years Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf22fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 成功合并所有文件\n",
      "  合并后形状: 392 行 × 5 列\n",
      "\n",
      "✓ 合并数据已保存到变量 'kff_combined'\n"
     ]
    }
   ],
   "source": [
    "# If all files have consistent column structure, merge them\n",
    "try:\n",
    "    combined_df = pd.concat(kff_data.values(), ignore_index=True)\n",
    "    print(f\"✓ Successfully merged all files\")\n",
    "    print(f\"  Combined shape: {combined_df.shape[0]:,} rows × {combined_df.shape[1]} columns\")\n",
    "    \n",
    "    # If there are year columns, display year distribution\n",
    "    year_cols = [col for col in combined_df.columns if 'year' in col.lower()]\n",
    "    if year_cols:\n",
    "        print(f\"\\nYear distribution (based on column '{year_cols[0]}'):\")\n",
    "        print(combined_df[year_cols[0]].value_counts().sort_index())\n",
    "    \n",
    "    # Store merged data to global variable\n",
    "    globals()['kff_combined'] = combined_df\n",
    "    print(\"\\n✓ Merged data saved to variable 'kff_combined'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Merge failed: {e}\")\n",
    "    print(\"  Files may have inconsistent column structure, check column structure first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc513c2",
   "metadata": {},
   "source": [
    "## Export Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85778094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export kff_combined to CSV file\n",
    "if 'kff_combined' in globals():\n",
    "    output_dir = Path('2433_p3_data/KFF_data/exports')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_file = output_dir / 'kff_combined_2020_2026.csv'\n",
    "    kff_combined.to_csv(output_file, index=False)\n",
    "    \n",
    "    file_size_mb = output_file.stat().st_size / 1024 / 1024\n",
    "    print(f\"✓ kff_combined exported to: {output_file}\")\n",
    "    print(f\"  Rows: {len(kff_combined):,}\")\n",
    "    print(f\"  Columns: {kff_combined.shape[1]}\")\n",
    "    print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"⚠ kff_combined not found. Please run the merge cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003b2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 所有KFF数据已保存到变量 'kff_data' (字典类型)\n",
      "  可用文件: ['raw_data_2020.csv', 'raw_data_2021.csv', 'raw_data_2022.csv', 'raw_data_2023.csv', 'raw_data_2024.csv', 'raw_data_2025.csv', 'raw_data_2026.csv']\n",
      "\n",
      "使用示例:\n",
      "  - 访问2020年数据: kff_data['raw_data_2020.csv']\n",
      "  - 访问合并数据: kff_combined (如果已执行合并)\n"
     ]
    }
   ],
   "source": [
    "# Save all data to global variables for subsequent use\n",
    "globals()['kff_data'] = kff_data\n",
    "print(f\"✓ All KFF data saved to variable 'kff_data' (dictionary type)\")\n",
    "print(f\"  Available files: {list(kff_data.keys())}\")\n",
    "print(f\"\\nUsage examples:\")\n",
    "print(\"  - Access 2020 data: kff_data['raw_data_2020.csv']\")\n",
    "print(\"  - Access merged data: kff_combined (if merge has been executed)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
