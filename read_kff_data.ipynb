{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7841ca13",
   "metadata": {},
   "source": [
    "# Read KFF Data Files\n",
    "\n",
    "This notebook reads all data files under `2433_p3_data/KFF_data/` directory and displays the first 5 rows of each file.\n",
    "\n",
    "KFF (Kaiser Family Foundation) data files contain healthcare-related statistics and information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052898c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置pandas显示选项\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义KFF数据目录\n",
    "KFF_DATA_DIR = Path('2433_p3_data/KFF_data')\n",
    "\n",
    "# 检查目录是否存在\n",
    "if not KFF_DATA_DIR.exists():\n",
    "    print(f\"错误: 目录 {KFF_DATA_DIR} 不存在!\")\n",
    "else:\n",
    "    print(f\"✓ 找到数据目录: {KFF_DATA_DIR}\")\n",
    "    print(f\"  绝对路径: {KFF_DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找所有数据文件\n",
    "data_files = sorted(list(KFF_DATA_DIR.glob('*.csv')))\n",
    "\n",
    "print(f\"发现 {len(data_files)} 个CSV文件:\")\n",
    "for i, file in enumerate(data_files, 1):\n",
    "    file_size = file.stat().st_size / 1024  # KB\n",
    "    print(f\"  {i}. {file.name} ({file_size:.2f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8713bd",
   "metadata": {},
   "source": [
    "## 读取所有KFF数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取所有CSV文件到字典中\n",
    "kff_data = {}\n",
    "errors = {}\n",
    "\n",
    "for file_path in data_files:\n",
    "    file_name = file_path.name\n",
    "    try:\n",
    "        print(f\"正在读取: {file_name}...\", end=\" \")\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        kff_data[file_name] = df\n",
    "        print(f\"✓ 成功 (形状: {df.shape})\")\n",
    "    except Exception as e:\n",
    "        errors[file_name] = str(e)\n",
    "        print(f\"✗ 失败: {e}\")\n",
    "\n",
    "print(f\"\\n总计: 成功读取 {len(kff_data)} 个文件, 失败 {len(errors)} 个文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c87d74",
   "metadata": {},
   "source": [
    "## 显示每个文件的前5行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示每个文件的前5行\n",
    "for i, (file_name, df) in enumerate(sorted(kff_data.items()), 1):\n",
    "    print(\"=\"*100)\n",
    "    print(f\"文件 {i}/{len(kff_data)}: {file_name}\")\n",
    "    print(f\"形状: {df.shape[0]:,} 行 × {df.shape[1]} 列\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # 显示列名\n",
    "    print(f\"\\n列名 ({len(df.columns)} 列):\")\n",
    "    print(list(df.columns))\n",
    "    \n",
    "    # 显示前5行\n",
    "    print(\"\\n前5行数据:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # 显示基本统计信息\n",
    "    print(\"\\n数据类型:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\n缺失值统计:\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"没有缺失值\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa3955",
   "metadata": {},
   "source": [
    "## 数据概览汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c66192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据概览汇总表\n",
    "summary_data = []\n",
    "\n",
    "for file_name, df in sorted(kff_data.items()):\n",
    "    summary_data.append({\n",
    "        '文件名': file_name,\n",
    "        '行数': df.shape[0],\n",
    "        '列数': df.shape[1],\n",
    "        '总缺失值': df.isnull().sum().sum(),\n",
    "        '缺失率(%)': f\"{(df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\",\n",
    "        '内存使用(MB)': f\"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"KFF数据文件汇总\")\n",
    "print(\"=\"*100)\n",
    "display(summary_df)\n",
    "\n",
    "print(f\"\\n总行数: {summary_df['行数'].sum():,}\")\n",
    "print(f\"平均列数: {summary_df['列数'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5ddba",
   "metadata": {},
   "source": [
    "## 检查数据一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查所有文件是否有相同的列结构\n",
    "if len(kff_data) > 0:\n",
    "    first_file = list(kff_data.keys())[0]\n",
    "    first_columns = set(kff_data[first_file].columns)\n",
    "    \n",
    "    print(\"列结构一致性检查:\")\n",
    "    all_same = True\n",
    "    \n",
    "    for file_name, df in kff_data.items():\n",
    "        current_columns = set(df.columns)\n",
    "        if current_columns == first_columns:\n",
    "            print(f\"  ✓ {file_name}: 列结构一致\")\n",
    "        else:\n",
    "            all_same = False\n",
    "            print(f\"  ✗ {file_name}: 列结构不同\")\n",
    "            missing = first_columns - current_columns\n",
    "            extra = current_columns - first_columns\n",
    "            if missing:\n",
    "                print(f\"    缺少的列: {missing}\")\n",
    "            if extra:\n",
    "                print(f\"    额外的列: {extra}\")\n",
    "    \n",
    "    if all_same:\n",
    "        print(\"\\n✓ 所有文件的列结构一致，可以安全地合并!\")\n",
    "    else:\n",
    "        print(\"\\n⚠ 文件列结构不一致，合并前需要进行对齐处理。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab99cd",
   "metadata": {},
   "source": [
    "## 可选: 合并所有年份的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果所有文件列结构一致，可以合并它们\n",
    "try:\n",
    "    combined_df = pd.concat(kff_data.values(), ignore_index=True)\n",
    "    print(f\"✓ 成功合并所有文件\")\n",
    "    print(f\"  合并后形状: {combined_df.shape[0]:,} 行 × {combined_df.shape[1]} 列\")\n",
    "    \n",
    "    # 如果有年份列，显示年份分布\n",
    "    year_cols = [col for col in combined_df.columns if 'year' in col.lower()]\n",
    "    if year_cols:\n",
    "        print(f\"\\n年份分布 (基于列 '{year_cols[0]}'):\")\n",
    "        print(combined_df[year_cols[0]].value_counts().sort_index())\n",
    "    \n",
    "    # 将合并后的数据存储到全局变量\n",
    "    globals()['kff_combined'] = combined_df\n",
    "    print(\"\\n✓ 合并数据已保存到变量 'kff_combined'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 合并失败: {e}\")\n",
    "    print(\"  文件列结构可能不一致，请先检查列结构。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc513c2",
   "metadata": {},
   "source": [
    "## 数据导出 (可选)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选: 将前5行数据导出为单独的预览文件\n",
    "preview_dir = Path('2433_p3_data/KFF_data/previews')\n",
    "preview_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"保存前5行预览文件...\")\n",
    "for file_name, df in kff_data.items():\n",
    "    preview_file = preview_dir / f\"{file_name.replace('.csv', '_preview.csv')}\"\n",
    "    df.head().to_csv(preview_file, index=False)\n",
    "    print(f\"  ✓ {preview_file.name}\")\n",
    "\n",
    "print(f\"\\n✓ 所有预览文件已保存到: {preview_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有数据保存到全局变量以便后续使用\n",
    "globals()['kff_data'] = kff_data\n",
    "print(f\"✓ 所有KFF数据已保存到变量 'kff_data' (字典类型)\")\n",
    "print(f\"  可用文件: {list(kff_data.keys())}\")\n",
    "print(f\"\\n使用示例:\")\n",
    "print(\"  - 访问2020年数据: kff_data['raw_data_2020.csv']\")\n",
    "print(\"  - 访问合并数据: kff_combined (如果已执行合并)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
